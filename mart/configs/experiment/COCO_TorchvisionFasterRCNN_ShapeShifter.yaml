# @package _global_

defaults:
  - COCO_TorchvisionFasterRCNN
  - /attack/perturber@model.modules.perturber: default
  - /attack/perturber/initializer@model.modules.perturber.initializer: uniform
  - /attack/perturber/composer@model.modules.perturber.composer: color_jitter_warp_overlay
  - /attack/perturber/projector@model.modules.perturber.projector: range
  - /attack/optimizer@model.optimizer: sgd
  - /attack/gradient_modifier@model.gradient_modifier: lp_normalizer

task_name: "COCO_TorchvisionFasterRCNN_ShapeShifter"
tags: ["adv"]

datamodule:
  num_workers: 8
  ims_per_batch: 2

model:
  modules:
    perturber:
      size: [3, 416, 416]

      initializer:
        min: 127
        max: 129

      composer:
        warp:
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: torchvision.transforms.RandomErasing
              p: 0.75
              scale: [0.2, 0.7]
              ratio: [0.3, 3.3]
            - _target_: torchvision.transforms.RandomAffine
              degrees: 0
              scale: [0.3, 0.5]
            - _target_: torchvision.transforms.RandomPerspective
              distortion_scale: 0.2
              p: 0.5
        clamp: [0, 255]
        brightness: [0.5, 1.5]
        contrast: [0.5, 1.5]
        saturation: [0.5, 1.0]
        hue: [-0.05, 0.05]
        pixel_scale: 255

    losses_and_detections:
      model:
        model:
          weights: "FasterRCNN_ResNet50_FPN_Weights.COCO_V1"

  # FIXME: Would be much nicer if we could specify _freeze_: True for each module
  freeze: "losses_and_detections"

  optimizer:
    lr: 25.5
    momentum: 0.9

  gradient_modifier:
    p: inf

  training_sequence:
    seq005: perturber

    seq010:
      preprocessor: ["perturber"]

  validation_sequence: ${.training_sequence}

  test_sequence: ${.validation_sequence}
