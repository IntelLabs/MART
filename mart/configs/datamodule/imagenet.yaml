defaults:
  - default.yaml

train_dataset:
  _target_: torchvision.datasets.ImageNet

  root: ${paths.data_dir}/imagenet/2012/
  split: train
  transform:
    _target_: torchvision.transforms.Compose
    transforms:
      - _target_: torchvision.transforms.RandomResizedCrop
        size: 224
      - _target_: torchvision.transforms.RandomHorizontalFlip
      - _target_: torchvision.transforms.ToTensor
      - _target_: mart.transforms.Denormalize
        center: 0
        scale: 255
      - _target_: torch.fake_quantize_per_tensor_affine
        _partial_: true
        # (x/1+0).round().clamp(0, 255) * 1
        scale: 1
        zero_point: 0
        quant_min: 0
        quant_max: 255

val_dataset:
  _target_: torchvision.datasets.ImageNet
  root: ${paths.data_dir}/imagenet/2012/
  split: val
  transform:
    _target_: torchvision.transforms.Compose
    transforms:
      - _target_: torchvision.transforms.CenterCrop
        size: 224
      - _target_: torchvision.transforms.ToTensor
      - _target_: mart.transforms.Denormalize
        center: 0
        scale: 255
      - _target_: torch.fake_quantize_per_tensor_affine
        _partial_: true
        # (x/1+0).round().clamp(0, 255) * 1
        scale: 1
        zero_point: 0
        quant_min: 0
        quant_max: 255

test_dataset: ${.val_dataset}

num_classes: 1000
