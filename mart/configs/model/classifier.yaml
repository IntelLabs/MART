defaults:
  - modular

# All three sequences of training/validation/test are (almost, except for the training loss) equivalent but in different syntax.

# The verbose version.
training_sequence:
  seq010:
    preprocessor:
      _call_with_args_: ["input"]
  seq020:
    logits:
      _call_with_args_: ["preprocessor"]
  seq030:
    loss:
      _call_with_args_: ["logits", "target"]
  seq040:
    preds:
      _call_with_args_: ["logits"]

# The kwargs-centric version.
# We may use *args as **kwargs to avoid the lengthy _call_with_args_.
#   The drawback is that we would need to lookup the *args names from the code.
# We use a list-style sequence since we don't care about replacing any elements.
validation_sequence:
  - preprocessor:
      tensor: input
  - logits: ["preprocessor"]
  - preds:
      input: logits

# The simplified version.
#   We treat a list as the `_call_with_args_` parameter.
test_sequence:
  seq010:
    preprocessor: ["input"]
  seq020:
    logits: ["preprocessor"]
  seq030:
    preds: ["logits"]

modules:
  preprocessor: ???

  logits: ???

  loss:
    _target_: torch.nn.CrossEntropyLoss

  preds:
    _target_: torch.nn.Softmax
    dim: 1
