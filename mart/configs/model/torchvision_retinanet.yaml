# We simply wrap a torchvision object detection model for validation.
defaults:
  - torchvision_object_detection

load_state_dict:
  detector:
    _target_: hydra.utils._locate # FIXME: Use hydra.utils.get_object when available
    path: "torchvision.models.detection.RetinaNet_ResNet50_FPN_Weights.COCO_V1"

# log all losses separately in training.
training_step_log:
  loss_classifier: "losses.classification"
  loss_box_reg: "losses.bbox_regression"

training_sequence:
  seq010:
    preprocessor: ["input"]

  seq020:
    detector:
      _name_: losses
      _train_mode_: True
      images: preprocessor
      targets: target

  seq030:
    detector:
      _name_: preds
      _train_mode_: False
      _inference_mode_: True
      images: preprocessor
      targets: target

  seq100:
    loss:
      # Sum up the losses.
      ["losses.classification", "losses.bbox_regression"]

validation_sequence:
  seq010:
    preprocessor: ["input"]

  seq020:
    detector:
      _name_: losses
      _train_mode_: True
      images: preprocessor
      targets: target

  seq030:
    detector:
      _name_: preds
      _train_mode_: False
      _inference_mode_: True
      images: preprocessor
      targets: target

test_sequence:
  seq010:
    preprocessor: ["input"]

  seq020:
    detector:
      _name_: losses
      _train_mode_: True
      images: preprocessor
      targets: target

  seq030:
    detector:
      _name_: preds
      _train_mode_: False
      _inference_mode_: True
      images: preprocessor
      targets: target

modules:
  detector:
    _target_: mart.nn.Module
    _path_: torchvision.models.detection.retinanet_resnet50_fpn
    num_classes: ???
