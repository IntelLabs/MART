# We simply wrap a torchvision object detection model for validation.
defaults:
  - torchvision_object_detection

# log all losses separately in training.
training_step_log:
  loss_classifier: "losses_and_detections.training.classification"
  loss_box_reg: "losses_and_detections.training.bbox_regression"

training_sequence:
  - preprocessor: ["input"]
  - losses_and_detections: ["preprocessor", "target"]
  - loss:
      # Sum up the losses.
      [
        "losses_and_detections.training.classification",
        "losses_and_detections.training.bbox_regression",
      ]

validation_sequence:
  - preprocessor: ["input"]
  - losses_and_detections: ["preprocessor", "target"]

test_sequence:
  - preprocessor: ["input"]
  - losses_and_detections: ["preprocessor", "target"]

modules:
  losses_and_detections:
    # _target_: mart.models.DualMode
    model:
      _target_: torchvision.models.detection.retinanet_resnet50_fpn
      num_classes: ???
