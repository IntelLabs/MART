# We simply wrap a torchvision object detection model for validation.
defaults:
  - torchvision_object_detection

# log all losses separately in losses.
training_step_log:
  loss_objectness: "losses.loss_objectness"
  loss_rpn_box_reg: "losses.loss_rpn_box_reg"
  loss_classifier: "losses.loss_classifier"
  loss_box_reg: "losses.loss_box_reg"

training_sequence:
  seq010:
    preprocessor: ["input"]

  seq020:
    detector:
      _name_: losses
      _train_mode_: True
      images: preprocessor
      targets: target

  seq030:
    detector:
      _name_: preds
      _train_mode_: False
      _inference_mode_: True
      images: preprocessor
      targets: target

  seq100:
    loss:
      # Sum up the losses.
      [
        "losses.loss_objectness",
        "losses.loss_rpn_box_reg",
        "losses.loss_classifier",
        "losses.loss_box_reg",
      ]

validation_sequence:
  seq010:
    preprocessor: ["input"]

  seq020:
    detector:
      _name_: losses
      _train_mode_: True
      images: preprocessor
      targets: target

  seq030:
    detector:
      _name_: preds
      _train_mode_: False
      _inference_mode_: True
      images: preprocessor
      targets: target

test_sequence:
  seq010:
    preprocessor: ["input"]

  seq020:
    detector:
      _name_: losses
      _train_mode_: True
      images: preprocessor
      targets: target

  seq030:
    detector:
      _name_: preds
      _train_mode_: False
      _inference_mode_: True
      images: preprocessor
      targets: target

modules:
  detector:
    _target_: mart.nn.Module
    _path_: torchvision.models.detection.fasterrcnn_resnet50_fpn
    weights: "COCO_V1"
